{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charts.common.dataset import LabeledImage\n",
    "from charts.common.timer import Timer\n",
    "import charts.pytorch.color_regression as cr\n",
    "import charts.pytorch.utils as utils\n",
    "from charts.pytorch.utils import Experiment, num_trainable_parameters, is_google_colab, merge_dicts\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision import transforms\n",
    "import torch.profiler\n",
    "\n",
    "import torch_lr_finder\n",
    "import timm\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from icecream import ic\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Use CUDA: True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "display(f\"Use CUDA: {use_cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RUN = False\n",
    "\n",
    "preprocessor = cr.ImagePreprocessor(device, target_size=128)\n",
    "\n",
    "dataset_path = Path(\"/content/datasets/drawings\") if is_google_colab() else Path('../../generated/drawings')\n",
    "\n",
    "dataset = cr.ColorRegressionImageDataset(dataset_path, preprocessor)\n",
    "n_train = max(int(len(dataset) * 0.5), 1)\n",
    "n_val = len(dataset) - n_train\n",
    "# train_dataset, val_dataset = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_indices = range(0, n_train)\n",
    "val_indices = range(n_train, len(dataset))\n",
    "\n",
    "small_subset = TEST_RUN or not is_google_colab()\n",
    "if small_subset:\n",
    "    N = 16\n",
    "    train_indices = random.sample(train_indices, N)\n",
    "    val_indices = random.sample(val_indices, N)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices, generator=generator)\n",
    "val_sampler = SubsetRandomSampler(val_indices, generator=generator)\n",
    "\n",
    "DEFAULT_BATCH_SIZE=64 if is_google_colab() else 4\n",
    "WORKERS=os.cpu_count() if is_google_colab() else 0\n",
    "\n",
    "monitored_train_samples = random.sample(train_indices, 5)\n",
    "monitored_val_samples = random.sample(val_indices, 5)\n",
    "# monitored_sample = dataset[0]\n",
    "# monitored_sample_inputs = torch.unsqueeze(monitored_sample[0], dim=0)\n",
    "# monitored_samples_json = ["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, name, batch_size=DEFAULT_BATCH_SIZE): \n",
    "        self.name = name\n",
    "        self.batch_size = batch_size\n",
    "    def create_net(self): return None\n",
    "    def create_optimizer(self, net): return None\n",
    "    def create_scheduler(self, optimizer, frozen, steps_per_epoch, total_epochs): return None\n",
    "    def get_hyperparams(self): return dict(name=self.name, batch=self.batch_size)\n",
    "\n",
    "net = None\n",
    "\n",
    "def run_xp_config (xp: Experiment, config: Config, frozen_epochs: int, total_epochs: int, profiler = None):\n",
    "    torch.cuda.empty_cache()\n",
    "    global net # Make sure that we keep the last net to play with it after.    \n",
    "    \n",
    "    # Make sure that we release as much memory as possible\n",
    "    net = None\n",
    "    utils.clear_gpu_memory()\n",
    "\n",
    "    net = config.create_net()\n",
    "    net.to(device)\n",
    "    optimizer = config.create_optimizer(net)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=config.batch_size, num_workers=WORKERS)\n",
    "    val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=config.batch_size, num_workers=WORKERS)\n",
    "     \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    run_lr_finder = False\n",
    "    if run_lr_finder:\n",
    "        lr_finder = torch_lr_finder.LRFinder(net, optimizer, criterion, device=\"cuda\")\n",
    "        lr_finder.range_test(train_dataloader, start_lr=1e-5, end_lr=1, num_iter=100)\n",
    "        lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "        lr_finder.reset() # to reset the model and optimizer to their initial state\n",
    "\n",
    "    val_accuracy = 0.0\n",
    "    training_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    def train (first_epoch, end_epoch, optimizer, scheduler):\n",
    "        pbar = tqdm(range(first_epoch, end_epoch))\n",
    "        for epoch in pbar:  # loop over the dataset multiple times\n",
    "            nonlocal training_loss, val_loss, val_accuracy\n",
    "            net.train()\n",
    "            cumulated_training_loss = 0.0\n",
    "            tstart = time.time()\n",
    "            \n",
    "            # batch_bar = tqdm(train_dataloader, leave=False)\n",
    "            for i, data in enumerate(train_dataloader):\n",
    "                inputs, labels, json_files = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                batch_loss = loss.item()\n",
    "                # xp.writer.add_scalar(\"Single Batch Loss\", batch_loss, epoch)\n",
    "\n",
    "                cumulated_training_loss += batch_loss\n",
    "\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "\n",
    "                if profiler:\n",
    "                    profiler.step()\n",
    "\n",
    "            # Very important for batch norm layers.\n",
    "            net.eval()\n",
    "\n",
    "            def evaluate_images_at_indices(indices):                \n",
    "                inputs = []\n",
    "                outputs = []\n",
    "                targets = []\n",
    "                for idx in indices:\n",
    "                    input, target = [x.to(device) for x in dataset[idx][:2]]\n",
    "                    output = net(input.unsqueeze(0)).squeeze(0)\n",
    "                    inputs.append(preprocessor.denormalize_and_clip_as_tensor(input.detach().cpu()))\n",
    "                    outputs.append(preprocessor.denormalize_and_clip_as_tensor(output.detach().cpu()))\n",
    "                    targets.append(preprocessor.denormalize_and_clip_as_tensor(target.detach().cpu()))\n",
    "                return torch.cat([torch.cat(outputs, dim=2), torch.cat(targets, dim=2), torch.cat(inputs, dim=2)], dim=1)\n",
    "\n",
    "            results_train = evaluate_images_at_indices(monitored_train_samples)\n",
    "            xp.writer.add_image(\"Train Samples\", results_train, epoch)\n",
    "\n",
    "            results_val = evaluate_images_at_indices(monitored_val_samples)\n",
    "            xp.writer.add_image(\"Val Samples\", results_val, epoch)\n",
    "\n",
    "            training_loss = cumulated_training_loss / len(train_dataloader)\n",
    "            xp.writer.add_scalar(\"Training Loss\", training_loss, epoch)\n",
    "            \n",
    "            val_loss = cr.compute_average_loss (val_dataloader, net, criterion, device)\n",
    "            xp.writer.add_scalar(\"Validation Loss\", val_loss, epoch)\n",
    "\n",
    "            val_accuracy = cr.compute_accuracy (val_dataloader, net, criterion, device)\n",
    "            xp.writer.add_scalar(\"Validation Accuracy\", val_accuracy, epoch)\n",
    "\n",
    "            elapsedSecs = (time.time() - tstart)\n",
    "            xp.writer.add_scalar(\"Elapsed Time (s)\", elapsedSecs, epoch)\n",
    "            # print(f\"[{epoch}] [TRAIN_LOSS={training_loss:.4f}] [VAL_LOSS={val_loss:.4f}] [{elapsedSecs:.1f}s]\")\n",
    "            \n",
    "            xp.writer.add_histogram(\"enc0\", net.decoder.enc0.block[3].weight, global_step=epoch)\n",
    "            xp.writer.add_histogram(\"dec0\", net.decoder.dec0.block[3].weight, global_step=epoch)\n",
    "\n",
    "            pbar.set_postfix({'train_loss': training_loss, 'val_loss': val_loss, 'val_accuracy': val_accuracy})\n",
    "\n",
    "            if epoch > 0 and epoch % 10 == 0:\n",
    "                xp.save_checkpoint(epoch)\n",
    "\n",
    "        xp.save_checkpoint(end_epoch-1)\n",
    "\n",
    "    net.freeze_encoder()\n",
    "    ic(num_trainable_parameters(net))\n",
    "    scheduler = config.create_scheduler(optimizer, frozen=True, steps_per_epoch=len(train_dataloader), total_epochs=frozen_epochs)\n",
    "    xp.prepare (config.name + '-frozen', net, optimizer, scheduler, device, dataset[0][0].unsqueeze(0).to(device))\n",
    "    xp.writer.add_text(\"Model Complexity\", \", \".join(get_model_complexity_info(net, (3, 128, 128), as_strings=True, print_per_layer_stat=False, verbose=False)), global_step=None, walltime=None)\n",
    "    train(xp.first_epoch, frozen_epochs, optimizer, scheduler)\n",
    "    xp.finalize(hparams = config.get_hyperparams(), metrics={'hparam/train_loss': training_loss, 'hparam/val_loss': val_loss, 'hparam/accuracy': val_accuracy})\n",
    "\n",
    "    utils.clear_gpu_memory()\n",
    "\n",
    "    net.unfreeze_encoder()\n",
    "    scheduler = config.create_scheduler(optimizer, frozen=False, steps_per_epoch=len(train_dataloader), total_epochs=(total_epochs - frozen_epochs))\n",
    "    xp.prepare (config.name + '-tune', net, optimizer, scheduler, device, dataset[0][0].unsqueeze(0).to(device), default_first_epoch=frozen_epochs)\n",
    "    ic(num_trainable_parameters(net))\n",
    "    train(xp.first_epoch, total_epochs, optimizer, scheduler)\n",
    "    xp.finalize(hparams = config.get_hyperparams(), metrics={'hparam/train_loss': training_loss, 'hparam/val_loss': val_loss, 'hparam/accuracy': val_accuracy})\n",
    "\n",
    "    print('Finished Training!')\n",
    "    utils.clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XP] storing experiment data to /content/drive/MyDrive/DaltonLens-Colab/DaltonLensPrivate/charts/pytorch/experiments/2022-Feb03-CR1\n",
      "=== [1/9] RUNNING CONFIG unet1_adamw_1cycle_bn64_3e4_3e4_1e5 ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_trainable_parameters(net): '18.3M'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XP] storing config data to /content/drive/MyDrive/DaltonLens-Colab/DaltonLensPrivate/charts/pytorch/experiments/2022-Feb03-CR1/unet1_adamw_1cycle_bn64_3e4_3e4_1e5-frozen\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c22e674dcf41bbb041495b24eeda44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a44158c98f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mrun_xp_config\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozen_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mrun_xp_config\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozen_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-ff7fdaedfd68>\u001b[0m in \u001b[0;36mrun_xp_config\u001b[0;34m(xp, config, frozen_epochs, total_epochs, profiler)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-frozen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model Complexity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_model_complexity_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_per_layer_stat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozen_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hyperparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'hparam/train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hparam/val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hparam/accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ff7fdaedfd68>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(first_epoch, end_epoch, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_accuracy\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/DaltonLens-Colab/DaltonLensPrivate/charts/pytorch/color_regression.py\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(dataset_loader, net, criterion, device)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mnum_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mnum_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "class ConfigUnet1Adam(Config):\n",
    "    def __init__(self, name, max_lr_frozen, max_lr_tune, one_cycle: bool = True, *args, **kwargs):\n",
    "        super().__init__(name, *args, **kwargs)\n",
    "        self.one_cycle = one_cycle\n",
    "        self.max_lr_frozen = max_lr_frozen\n",
    "        self.max_lr_tune = max_lr_tune\n",
    "\n",
    "    def create_net(self): return cr.RegressionNet_Unet1()\n",
    "\n",
    "    def create_optimizer(self, net): \n",
    "        return optim.Adam([\n",
    "            {'params': net.encoder.parameters(), 'lr': self.max_lr_frozen[0] },\n",
    "            {'params': net.decoder.parameters(), 'lr': self.max_lr_frozen[1] }\n",
    "        ])\n",
    "\n",
    "    def create_scheduler(self, optimizer, frozen: bool, steps_per_epoch: int, total_epochs: int):\n",
    "        if not self.one_cycle:\n",
    "            return None\n",
    "        max_lr = self.max_lr_frozen if frozen else self.max_lr_tune\n",
    "        return torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, steps_per_epoch=steps_per_epoch, epochs=total_epochs)\n",
    "\n",
    "    def get_hyperparams(self):\n",
    "        return merge_dicts(super().get_hyperparams(), dict(\n",
    "            net='unet1',\n",
    "            opt='adam',\n",
    "            sched='1cycle' if self.one_cycle else 'none',\n",
    "            enc_lr_frozen=self.max_lr_frozen[0],\n",
    "            dec_lr_frozen=self.max_lr_frozen[1],\n",
    "            enc_lr_tune=self.max_lr_tune[0],\n",
    "            dec_lr_tune=self.max_lr_tune[1]\n",
    "        ))\n",
    "\n",
    "class ConfigUnet1AdamW(ConfigUnet1Adam):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def create_optimizer(self, net): \n",
    "        return optim.AdamW([\n",
    "            {'params': net.encoder.parameters(), 'lr': self.max_lr_frozen[0] },\n",
    "            {'params': net.decoder.parameters(), 'lr': self.max_lr_frozen[1] }\n",
    "        ])\n",
    "\n",
    "    def get_hyperparams(self):\n",
    "        return merge_dicts(super().get_hyperparams(), dict(opt='AdamW'))\n",
    "\n",
    "class ConfigUnet1SGD(ConfigUnet1Adam):\n",
    "    def __init__(self, name, momentum, *args, **kwargs):\n",
    "        super().__init__(name, *args, **kwargs)\n",
    "        self.momentum = momentum\n",
    "    \n",
    "    def create_optimizer(self, net):\n",
    "        return optim.SGD([\n",
    "            {'params': net.encoder.parameters(), 'lr': self.max_lr_frozen[0] },\n",
    "            {'params': net.decoder.parameters(), 'lr': self.max_lr_frozen[1] }\n",
    "        ], momentum=self.momentum)\n",
    "\n",
    "    def get_hyperparams(self):\n",
    "        return merge_dicts(super().get_hyperparams(), dict(opt='SGD'))\n",
    "\n",
    "configs = [\n",
    "    # TODO: test diffent batch sizes and lr with AdamW\n",
    "    # ConfigUnet1Adam('unet1_adam_3e4', max_lr_frozen=(1e-5, 3e-4), max_lr_tune=(1e-5, 3e-4), one_cycle=False),\n",
    "\n",
    "    # ConfigUnet1Adam('unet1_adam_1cycle_1e3', max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4)),\n",
    "    # ConfigUnet1Adam('unet1_adam_1cycle_3e4', max_lr_frozen=(1e-5, 3e-4), max_lr_tune=(1e-5, 1e-4)),\n",
    "    \n",
    "    # ConfigUnet1SGD('unet1_sgd_1cycle_1e3_09', max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4), momentum=0.9),\n",
    "    # ConfigUnet1SGD('unet1_sgd_1cycle_1e3_099', max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4), momentum=0.99),\n",
    "\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_1e3_3e4', max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4)),\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_3e4_1e4', max_lr_frozen=(1e-5, 3e-4), max_lr_tune=(1e-5, 1e-4)),\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_3e4_3e4', max_lr_frozen=(1e-5, 3e-4), max_lr_tune=(1e-5, 3e-4)),\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_1e3_1e3', max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 1e-3)),\n",
    "\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_bn128_1e3_3e4', batch_size=128, max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4)),\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_1e3_3e4', batch_size=64, max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4)),\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_bn32_1e3_3e4', batch_size=32, max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4)),\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_bn16_1e3_3e4', batch_size=16, max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4)),\n",
    "\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_3e4_3e4', batch_size=64, max_lr_frozen=(1e-5, 3e-4), max_lr_tune=(1e-5, 3e-4)),\n",
    "    # ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_5e3_1e3', batch_size=64, max_lr_frozen=(1e-5, 5e-3), max_lr_tune=(1e-5, 1e-3)),\n",
    "\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_3e4_3e4_1e5', batch_size=64, max_lr_frozen=(1e-5, 3e-4), max_lr_tune=(1e-5, 3e-4)),\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_1e3_3e4_1e5', batch_size=64, max_lr_frozen=(1e-5, 1e-3), max_lr_tune=(1e-5, 3e-4)),\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_5e3_1e3_1e5', batch_size=64, max_lr_frozen=(1e-5, 5e-3), max_lr_tune=(1e-5, 1e-3)),\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_1e2_5e3_1e5', batch_size=64, max_lr_frozen=(1e-5, 1e-2), max_lr_tune=(1e-5, 5e-3)),\n",
    "\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_3e4_3e4_1e4', batch_size=64, max_lr_frozen=(1e-5, 3e-4), max_lr_tune=(1e-4, 3e-4)),\n",
    "\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_5e3_1e3_1e4', batch_size=64, max_lr_frozen=(1e-5, 5e-3), max_lr_tune=(1e-4, 1e-3)),\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_5e3_1e3_1e3', batch_size=64, max_lr_frozen=(1e-5, 5e-3), max_lr_tune=(1e-3, 1e-3)),\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_5e3_1e3_5e3', batch_size=64, max_lr_frozen=(1e-5, 5e-3), max_lr_tune=(5e-3, 1e-3)),\n",
    "    ConfigUnet1AdamW('unet1_adamw_1cycle_bn64_5e3_5e3_5e3', batch_size=64, max_lr_frozen=(1e-5, 5e-3), max_lr_tune=(5e-3, 5e-3)),\n",
    "]\n",
    "\n",
    "# with torch.profiler.profile(\n",
    "#     activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "#     schedule=torch.profiler.schedule(\n",
    "#         wait=2,\n",
    "#         warmup=2,\n",
    "#         active=6,\n",
    "#         repeat=1),\n",
    "#     on_trace_ready=torch.profiler.tensorboard_trace_handler(utils.default_output_dir / 'profiler'),\n",
    "#     with_stack=True\n",
    "# ) as profiler:\n",
    "#     xp = Experiment(\"2022-Feb01-CR1-Profiler\", utils.default_output_dir, clear_previous_results=True, clear_top_folder=True)\n",
    "#     print (f\"=== RUNNING PROFILING CONFIG {configs[0].name} ==\")\n",
    "#     run_xp_config (xp, configs[0], frozen_epochs=1, total_epochs=1, profiler=profiler)\n",
    "\n",
    "logs_root_dir = utils.default_output_dir\n",
    "xp = Experiment(\"2022-Feb03-CR1\" + ('TESTRUN' if TEST_RUN else ''), logs_root_dir, clear_previous_results=False, clear_top_folder=False)\n",
    "for i, config in enumerate(configs):\n",
    "    print (f\"=== [{i+1}/{len(configs)}] RUNNING CONFIG {config.name} ==\")\n",
    "    if TEST_RUN:\n",
    "        run_xp_config (xp, config, frozen_epochs=2, total_epochs=4)\n",
    "    else:\n",
    "        run_xp_config (xp, config, frozen_epochs=40, total_epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_specific_checkpoint (name):\n",
    "    checkpoint = torch.load(xp.log_path / name, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# load_specific_checkpoint (\"checkpoint-00701.pt\")\n",
    "# torch.save (net, \"regression_unet_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input, labels, _ = next(iter(train_dataloader))\n",
    "    input, labels = [x.to(device) for x in [input, labels]]\n",
    "    output = net(input.to(device))\n",
    "    #clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(output[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(labels[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the google colab VM\n",
    "if not TEST_RUN:\n",
    "    utils.stop_google_colab_vm ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "016a8caea8d0bcbcb0f585ee40a090ed0405075dd6b5b528270a2e6b8c256090"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
