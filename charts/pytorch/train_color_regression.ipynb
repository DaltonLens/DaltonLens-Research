{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q torchvision pandas\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charts.common.dataset import LabeledImage\n",
    "from charts.common.timer import Timer\n",
    "import charts.pytorch.color_regression as cr\n",
    "from charts.pytorch.utils import Experiment, num_trainable_parameters, is_google_colab\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch_lr_finder\n",
    "import timm\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from icecream import ic\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Use CUDA: True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "display(f\"Use CUDA: {use_cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = cr.ImagePreprocessor(device)\n",
    "\n",
    "dataset_path = Path(\"/content/datasets/drawings\") if is_google_colab() else Path('../../generated/drawings')\n",
    "dataset = cr.ColorRegressionImageDataset(dataset_path, preprocessor)\n",
    "n_train = max(int(len(dataset) * 0.75), 1)\n",
    "# n_val = len(dataset) - n_train\n",
    "# train_dataset, val_dataset = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_indices = range(0, n_train)\n",
    "val_indices = range(n_train, len(dataset))\n",
    "train_sampler = SubsetRandomSampler(train_indices, generator=generator)\n",
    "val_sampler = SubsetRandomSampler(val_indices, generator=generator)\n",
    "\n",
    "BATCH_SIZE=16 if is_google_colab() else 4\n",
    "\n",
    "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "monitored_sample = dataset[0]\n",
    "monitored_sample_inputs = torch.unsqueeze(monitored_sample[0], dim=0)\n",
    "monitored_sample_json = monitored_sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will store the experiment data to /content/drive/MyDrive/DaltonLens-Colab/DaltonLensPrivate/charts/pytorch/experiments/2022-Jan31-CR1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_trainable_parameters(net): 29508035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: removing the existing /content/drive/MyDrive/DaltonLens-Colab/DaltonLensPrivate/charts/pytorch/experiments/2022-Jan31-CR1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_trainable_parameters(net): 18331523\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cfa14b6b7f4f02baa29e335b4b6d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xp = Experiment(\"2022-Jan31-CR1\", clear_previous_results=True)\n",
    "\n",
    "net = cr.RegressionNet_Unet1()\n",
    "\n",
    "# get_model_complexity_info(net, (3, 256, 256), as_strings=True, print_per_layer_stat=True, verbose=False)\n",
    "\n",
    "ic(num_trainable_parameters(net))\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# print (f\"Initial training loss: {samecolors.compute_average_loss (train_dataloader, net, criterion)}\")\n",
    "# print (f\"Initial validation loss: {samecolors.compute_average_loss (val_dataloader, net, criterion)}\")\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.encoder.parameters(), 'lr': 1e-3 },\n",
    "    {'params': net.decoder.parameters(), 'lr': 1e-5 }\n",
    "])\n",
    "\n",
    "xp.prepare (net, optimizer, device, monitored_sample_inputs)\n",
    "\n",
    "def train (first_epoch, end_epoch, optimizer, max_lr):\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, steps_per_epoch=len(train_dataloader), epochs=(end_epoch-first_epoch))\n",
    "    pbar = tqdm(range(first_epoch, end_epoch))\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "\n",
    "        net.train()\n",
    "        cumulated_training_loss = 0.0\n",
    "        tstart = time.time()\n",
    "        \n",
    "        # batch_bar = tqdm(train_dataloader, leave=False)\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs, labels, json_files = data\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            xp.writer.add_scalar(\"Single Batch Loss\", batch_loss, epoch)\n",
    "\n",
    "            cumulated_training_loss += batch_loss\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            try:\n",
    "                idx = json_files.index(monitored_sample_json)\n",
    "                # t.stop()\n",
    "                \n",
    "                xp.writer.add_image(\"Sample output\", preprocessor.denormalize_and_clip_as_tensor(outputs[idx]), epoch)\n",
    "                xp.writer.add_image(\"Target output\", preprocessor.denormalize_and_clip_as_tensor(labels[idx]), epoch)\n",
    "                xp.writer.add_image(\"Sample input\",  preprocessor.denormalize_and_clip_as_tensor(inputs[idx]), epoch)\n",
    "            except ValueError: # monitored_json not in the batch\n",
    "                pass\n",
    "        \n",
    "\n",
    "        # Very important for batch norm layers.\n",
    "        net.eval()\n",
    "\n",
    "        training_loss = cumulated_training_loss / len(train_dataloader)\n",
    "        xp.writer.add_scalar(\"Training Loss\", training_loss, epoch)\n",
    "        \n",
    "        val_loss = cr.compute_average_loss (val_dataloader, net, criterion)\n",
    "        xp.writer.add_scalar(\"Validation Loss\", val_loss, epoch)\n",
    "\n",
    "        val_accuracy = cr.compute_accuracy (val_dataloader, net, criterion)\n",
    "        xp.writer.add_scalar(\"Validation Accuracy\", val_accuracy, epoch)\n",
    "\n",
    "        elapsedSecs = (time.time() - tstart)\n",
    "        xp.writer.add_scalar(\"Elapsed Time (s)\", elapsedSecs, epoch)\n",
    "        # print(f\"[{epoch}] [TRAIN_LOSS={training_loss:.4f}] [VAL_LOSS={val_loss:.4f}] [{elapsedSecs:.1f}s]\")\n",
    "        \n",
    "        xp.writer.add_histogram(\"enc0\", net.decoder.enc0.block[3].weight, global_step=epoch)\n",
    "        xp.writer.add_histogram(\"dec0\", net.decoder.dec0.block[3].weight, global_step=epoch)\n",
    "\n",
    "        pbar.set_postfix({'train_loss': training_loss, 'val_loss': val_loss, 'val_accuracy': val_accuracy})\n",
    "\n",
    "        if epoch % 5 == 1:\n",
    "            xp.save_checkpoint(epoch)\n",
    "\n",
    "FROZEN_EPOCHS=100\n",
    "TOTAL_EPOCHS=200\n",
    "\n",
    "net.freeze_encoder()\n",
    "ic(num_trainable_parameters(net))\n",
    "train(xp.first_epoch, FROZEN_EPOCHS, optimizer, max_lr=(1e-5, 1e-3))\n",
    "\n",
    "net.unfreeze_encoder()\n",
    "ic(num_trainable_parameters(net))\n",
    "train(FROZEN_EPOCHS, TOTAL_EPOCHS, optimizer, max_lr=(1e-5, 3e-4))\n",
    "\n",
    "print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_specific_checkpoint (name):\n",
    "    checkpoint = torch.load(xp.log_path / name, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# load_specific_checkpoint (\"checkpoint-00701.pt\")\n",
    "# torch.save (net, \"regression_unet_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input, labels, _ = next(iter(train_dataloader))\n",
    "    output = net(input)\n",
    "    #clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(input[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(output[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "016a8caea8d0bcbcb0f585ee40a090ed0405075dd6b5b528270a2e6b8c256090"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
