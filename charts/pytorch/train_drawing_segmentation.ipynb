{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q torchvision pandas\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charts.common.dataset import LabeledImage\n",
    "from charts.common.timer import Timer\n",
    "import charts.pytorch.similar_colors as samecolors\n",
    "import charts.pytorch.drawing_segmentation as ds\n",
    "from charts.pytorch.utils import Experiment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use CUDA: True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "display(f\"Use CUDA: {use_cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ds.Preprocessor(device)\n",
    "\n",
    "dataset = ds.DrawingSegmentationDataset(Path('../../generated/drawings'), preprocessor) # , max_length=8)\n",
    "n_train = max(len(dataset) // 2, 1)\n",
    "# n_val = len(dataset) - n_train\n",
    "# train_dataset, val_dataset = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_indices = range(0, n_train)\n",
    "val_indices = range(n_train, len(dataset))\n",
    "train_sampler = SubsetRandomSampler(train_indices, generator=generator)\n",
    "val_sampler = SubsetRandomSampler(val_indices, generator=generator)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=4)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=4)\n",
    "\n",
    "monitored_sample = dataset[0]\n",
    "monitored_sample_inputs = (torch.unsqueeze(monitored_sample[0][0], dim=0), torch.unsqueeze(monitored_sample[0][1], dim=0))\n",
    "monitored_sample_json = monitored_sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will store the experiment data to /home/nb/Perso/DaltonLensPrivate/charts/pytorch/experiments/drawing_segmentation/2021-Dec17-Unet1\n",
      "Warning: removing the existing /home/nb/Perso/DaltonLensPrivate/charts/pytorch/experiments/drawing_segmentation/2021-Dec17-Unet1\n",
      "[0] [TRAIN_LOSS=5.5550] [VAL_LOSS=4.5121] [2800.9s]\n"
     ]
    }
   ],
   "source": [
    "xp = Experiment(\"drawing_segmentation/2021-Dec17-Unet1\", clear_previous_results=True)\n",
    "\n",
    "net = ds.DrawSegmentation_Unet1()\n",
    "net.to(device)\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def drawing_loss(outputs: tuple, targets: tuple):\n",
    "    loss = torch.tensor(0.0).to(device)\n",
    "    for k in range(0, len(outputs)):\n",
    "        loss += cross_entropy_loss(outputs[k], targets[k])    \n",
    "    return loss\n",
    "\n",
    "criterion = drawing_loss\n",
    "\n",
    "# print (f\"Initial training loss: {samecolors.compute_average_loss (train_dataloader, net, criterion)}\")\n",
    "# print (f\"Initial validation loss: {samecolors.compute_average_loss (val_dataloader, net, criterion)}\")\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "xp.prepare (net, optimizer, device, monitored_sample_inputs)\n",
    "\n",
    "for epoch in range(xp.first_epoch, 1000):  # loop over the dataset multiple times\n",
    "\n",
    "    average_training_loss = 0.0\n",
    "    tstart = time.time()\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, targets, json_files = data\n",
    "\n",
    "        outputs = net(*inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        xp.writer.add_scalar(\"Single Batch Loss\", batch_loss, epoch)\n",
    "\n",
    "        average_training_loss += batch_loss\n",
    "\n",
    "        try:\n",
    "            idx = json_files.index(monitored_sample_json)\n",
    "            # t.stop()\n",
    "\n",
    "            # (2,H,W)\n",
    "            drawing_output_for_idx = outputs[0][idx]\n",
    "            # First apply softmax on the two classes.\n",
    "            # Then take only channel 1 to get the softmax score for class 1.\n",
    "            # Then unsqueeze it to add a channel dimension of 1 to please the writer.\n",
    "            drawing_softmax_output_for_class1 = torch.softmax(drawing_output_for_idx, dim=0)[1].unsqueeze(0)\n",
    "\n",
    "            xp.writer.add_image(\"_Input\",  preprocessor.denormalize_and_clip_as_tensor(inputs[0][idx]), epoch)\n",
    "            \n",
    "            xp.writer.add_image(\"Drawing/Bg: output\", drawing_softmax_output_for_class1, epoch)\n",
    "            xp.writer.add_image(\"Drawing/Bg: target\", targets[0][idx].unsqueeze(0), epoch)\n",
    "\n",
    "            L_output_for_idx = outputs[1][idx]\n",
    "            best_L = torch.argmax(L_output_for_idx, dim=0).unsqueeze(0)\n",
    "            target_L = targets[1][idx].unsqueeze(0)\n",
    "\n",
    "            xp.writer.add_image(\"L class / Output\", (best_L * 255/8).type(torch.ByteTensor), epoch)\n",
    "            xp.writer.add_image(\"L class / Target\", (target_L * 255/8).type(torch.ByteTensor), epoch)\n",
    "\n",
    "        except ValueError: # monitored_json not in the batch\n",
    "            pass\n",
    "    \n",
    "    average_training_loss = average_training_loss / len(train_dataloader)\n",
    "    xp.writer.add_scalar(\"Average Training Loss\", average_training_loss, epoch)\n",
    "\n",
    "    average_val_loss = ds.compute_average_loss (val_dataloader, net, criterion)\n",
    "    xp.writer.add_scalar(\"Average Validation Loss\", average_val_loss, epoch)\n",
    "\n",
    "    elapsedSecs = (time.time() - tstart)\n",
    "    xp.writer.add_scalar(\"Elapsed Time (s)\", elapsedSecs, epoch)\n",
    "    print(f\"[{epoch}] [TRAIN_LOSS={average_training_loss:.4f}] [VAL_LOSS={average_val_loss:.4f}] [{elapsedSecs:.1f}s]\")\n",
    "\n",
    "    if epoch % 10 == 1:\n",
    "        xp.save_checkpoint(epoch)\n",
    "\n",
    "print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_specific_checkpoint (name):\n",
    "    checkpoint = torch.load(xp.log_path / name, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# load_specific_checkpoint (\"checkpoint-00701.pt\")\n",
    "# torch.save (net, \"regression_unet_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input, labels, _ = next(iter(train_dataloader))\n",
    "    output = net(input)\n",
    "    #clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(input[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(output[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "016a8caea8d0bcbcb0f585ee40a090ed0405075dd6b5b528270a2e6b8c256090"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
