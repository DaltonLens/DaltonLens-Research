{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "is_google_colab = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q torchvision pandas\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charts.common.dataset import LabeledImage\n",
    "from charts.common.timer import Timer\n",
    "import charts.pytorch.similar_colors as samecolors\n",
    "import charts.pytorch.drawing_segmentation as ds\n",
    "from charts.pytorch.utils import Experiment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.profiler\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Use CUDA: True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "display(f\"Use CUDA: {use_cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ds.Preprocessor(device)\n",
    "\n",
    "if is_google_colab:\n",
    "    dataset_dir = Path('/content/datasets/drawings')\n",
    "else:\n",
    "    dataset_dir = Path('../../generated/drawings')\n",
    "\n",
    "dataset = ds.DrawingSegmentationDataset(dataset_dir, preprocessor, max_length=256)\n",
    "n_train = max(len(dataset) // 2, 1)\n",
    "# n_val = len(dataset) - n_train\n",
    "# train_dataset, val_dataset = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(42))\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_indices = range(0, n_train)\n",
    "val_indices = range(n_train, len(dataset))\n",
    "train_sampler = SubsetRandomSampler(train_indices, generator=generator)\n",
    "val_sampler = SubsetRandomSampler(val_indices, generator=generator)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, sampler=train_sampler, batch_size=16)\n",
    "val_dataloader = DataLoader(dataset, sampler=val_sampler, batch_size=16)\n",
    "\n",
    "monitored_sample = dataset[0]\n",
    "monitored_sample_inputs = (torch.unsqueeze(monitored_sample[0][0], dim=0), torch.unsqueeze(monitored_sample[0][1], dim=0))\n",
    "monitored_sample_json = monitored_sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will store the experiment data to /content/drive/MyDrive/DaltonLens-Colab/DaltonLensPrivate/charts/pytorch/experiments/drawing_segmentation/2021-Dec20-Unet1\n",
      "Loading checkpoint /content/drive/MyDrive/DaltonLens-Colab/DaltonLensPrivate/charts/pytorch/experiments/drawing_segmentation/2021-Dec20-Unet1/checkpoint-00011.pt\n",
      "[11] [TRAIN_LOSS=3.9660] [VAL_LOSS=4.5557] [20.7s]\n",
      "[12] [TRAIN_LOSS=3.7347] [VAL_LOSS=4.1568] [20.7s]\n",
      "[13] [TRAIN_LOSS=3.5221] [VAL_LOSS=4.1941] [20.5s]\n",
      "[14] [TRAIN_LOSS=3.4250] [VAL_LOSS=4.8976] [20.5s]\n",
      "[15] [TRAIN_LOSS=3.8277] [VAL_LOSS=4.2363] [20.5s]\n",
      "[16] [TRAIN_LOSS=3.7108] [VAL_LOSS=3.9022] [20.6s]\n",
      "[17] [TRAIN_LOSS=3.5027] [VAL_LOSS=3.9658] [20.5s]\n",
      "[18] [TRAIN_LOSS=3.4214] [VAL_LOSS=4.1487] [20.5s]\n",
      "[19] [TRAIN_LOSS=3.2553] [VAL_LOSS=3.6699] [20.5s]\n",
      "[20] [TRAIN_LOSS=3.0812] [VAL_LOSS=3.5931] [20.6s]\n",
      "[21] [TRAIN_LOSS=3.2642] [VAL_LOSS=3.9824] [20.6s]\n",
      "[22] [TRAIN_LOSS=3.2980] [VAL_LOSS=4.2968] [23.5s]\n",
      "[23] [TRAIN_LOSS=3.3251] [VAL_LOSS=3.7019] [20.6s]\n",
      "[24] [TRAIN_LOSS=3.0020] [VAL_LOSS=3.8573] [21.6s]\n",
      "[25] [TRAIN_LOSS=3.1870] [VAL_LOSS=3.7951] [20.6s]\n",
      "[26] [TRAIN_LOSS=3.0239] [VAL_LOSS=3.5258] [22.2s]\n",
      "[27] [TRAIN_LOSS=2.9592] [VAL_LOSS=3.7734] [21.2s]\n",
      "[28] [TRAIN_LOSS=3.0191] [VAL_LOSS=4.0697] [20.7s]\n",
      "[29] [TRAIN_LOSS=2.9172] [VAL_LOSS=3.5214] [22.5s]\n",
      "[30] [TRAIN_LOSS=2.7370] [VAL_LOSS=3.4708] [20.8s]\n",
      "[31] [TRAIN_LOSS=2.7676] [VAL_LOSS=3.5127] [20.6s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8219/620044880.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8219/620044880.py\u001b[0m in \u001b[0;36mdrawing_loss\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdrawing_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xp = Experiment(\"drawing_segmentation/2021-Dec20-Unet1\", clear_previous_results=False)\n",
    "\n",
    "net = ds.DrawSegmentation_Unet1()\n",
    "net.to(device)\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def drawing_loss(outputs: tuple, targets: tuple):\n",
    "    loss = torch.tensor(0.0).to(device)\n",
    "    for k in range(0, len(outputs)):\n",
    "        loss += cross_entropy_loss(outputs[k], targets[k])    \n",
    "    return loss\n",
    "\n",
    "criterion = drawing_loss\n",
    "\n",
    "# print (f\"Initial training loss: {samecolors.compute_average_loss (train_dataloader, net, criterion)}\")\n",
    "# print (f\"Initial validation loss: {samecolors.compute_average_loss (val_dataloader, net, criterion)}\")\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "xp.prepare (net, optimizer, device, monitored_sample_inputs)\n",
    "\n",
    "# prof = torch.profiler.profile(\n",
    "#         schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "#         on_trace_ready=torch.profiler.tensorboard_trace_handler(xp.log_path / 'profiler'),\n",
    "#         record_shapes=True,\n",
    "#         with_stack=True)\n",
    "# prof.start()\n",
    "\n",
    "for epoch in range(xp.first_epoch, 1000):  # loop over the dataset multiple times\n",
    "\n",
    "    average_training_loss = 0.0\n",
    "    tstart = time.time()\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, targets, json_files = data\n",
    "\n",
    "        outputs = net(*inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        xp.writer.add_scalar(\"Single Batch Loss\", batch_loss, epoch)\n",
    "\n",
    "        average_training_loss += batch_loss\n",
    "\n",
    "        # prof.step()\n",
    "\n",
    "        try:\n",
    "            idx = json_files.index(monitored_sample_json)\n",
    "            # t.stop()\n",
    "\n",
    "            # (2,H,W)\n",
    "            drawing_output_for_idx = outputs[0][idx]\n",
    "            # First apply softmax on the two classes.\n",
    "            # Then take only channel 1 to get the softmax score for class 1.\n",
    "            # Then unsqueeze it to add a channel dimension of 1 to please the writer.\n",
    "            drawing_softmax_output_for_class1 = torch.softmax(drawing_output_for_idx, dim=0)[1].unsqueeze(0)\n",
    "\n",
    "            xp.writer.add_image(\"_Input\",  preprocessor.denormalize_and_clip_as_tensor(inputs[0][idx]), epoch)\n",
    "            \n",
    "            xp.writer.add_image(\"Drawing/Bg: output\", drawing_softmax_output_for_class1, epoch)\n",
    "            xp.writer.add_image(\"Drawing/Bg: target\", targets[0][idx].unsqueeze(0), epoch)\n",
    "\n",
    "            L_output_for_idx = outputs[1][idx]\n",
    "            best_L = torch.argmax(L_output_for_idx, dim=0).unsqueeze(0)\n",
    "            target_L = targets[1][idx].unsqueeze(0)\n",
    "\n",
    "            xp.writer.add_image(\"L class / Output\", (best_L * 255/8).type(torch.ByteTensor), epoch)\n",
    "            xp.writer.add_image(\"L class / Target\", (target_L * 255/8).type(torch.ByteTensor), epoch)\n",
    "\n",
    "        except ValueError: # monitored_json not in the batch\n",
    "            pass\n",
    "    \n",
    "    # prof.stop()\n",
    "\n",
    "    average_training_loss = average_training_loss / len(train_dataloader)\n",
    "    xp.writer.add_scalar(\"Average Training Loss\", average_training_loss, epoch)\n",
    "\n",
    "    average_val_loss = ds.compute_average_loss (val_dataloader, net, criterion)\n",
    "    xp.writer.add_scalar(\"Average Validation Loss\", average_val_loss, epoch)\n",
    "\n",
    "    elapsedSecs = (time.time() - tstart)\n",
    "    xp.writer.add_scalar(\"Elapsed Time (s)\", elapsedSecs, epoch)\n",
    "    print(f\"[{epoch}] [TRAIN_LOSS={average_training_loss:.4f}] [VAL_LOSS={average_val_loss:.4f}] [{elapsedSecs:.1f}s]\")\n",
    "\n",
    "    if epoch % 10 == 1:\n",
    "        xp.save_checkpoint(epoch)\n",
    "\n",
    "print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_specific_checkpoint (name):\n",
    "    checkpoint = torch.load(xp.log_path / name, map_location=device)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# load_specific_checkpoint (\"checkpoint-00701.pt\")\n",
    "# torch.save (net, \"regression_unet_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input, labels, _ = next(iter(train_dataloader))\n",
    "    output = net(input)\n",
    "    #clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(input[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(output[0]))\n",
    "    plt.figure()\n",
    "    plt.imshow (preprocessor.denormalize_and_clip_as_numpy(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "016a8caea8d0bcbcb0f585ee40a090ed0405075dd6b5b528270a2e6b8c256090"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
